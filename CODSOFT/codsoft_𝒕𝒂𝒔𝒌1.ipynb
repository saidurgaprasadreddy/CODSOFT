{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "cNFY_GbeKw6o",
    "outputId": "79892dd5-627a-48ec-96bc-9abc43e81cf3",
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Install the Kaggle library\n",
    "!pip install kaggle\n",
    "\n",
    "# Upload your Kaggle API token (kaggle.json file)\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "# Move the kaggle.json file to the .kaggle folder\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Download the dataset from Kaggle\n",
    "!kaggle datasets download -d hijest/genre-classification-dataset-imdb\n",
    "\n",
    "# Unzip the dataset\n",
    "!unzip genre-classification-dataset-imdb.zip\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "df_train = pd.read_csv('/content/Genre Classification Dataset/train_data.txt', delimiter=':::', engine='python', names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'])\n",
    "\n",
    "# Load the test dataset (for later evaluation)\n",
    "df_test = pd.read_csv('/content/Genre Classification Dataset/test_data.txt', delimiter=':::', engine='python', names=['ID', 'TITLE', 'DESCRIPTION'])\n",
    "\n",
    "# Check the structure of the training dataset\n",
    "df_train.head()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uthDI6G7K7nj",
    "outputId": "69f01a7a-5c1c-42dd-ce92-59e905678914",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df_train['DESCRIPTION']\n",
    "y = df_train['GENRE']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer (convert text to numeric form)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit and transform the training data, transform validation data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n"
   ],
   "metadata": {
    "id": "IrYd-enMLaNP"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_nb = nb_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_val, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_nb))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJmB3OCIMeYZ",
    "outputId": "d6b43098-5c03-4494-861f-9485d911013c"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes Accuracy: 0.5231946878170248\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      action        0.58      0.08      0.14       263\n",
      "       adult        0.88      0.06      0.12       112\n",
      "   adventure        0.29      0.03      0.05       139\n",
      "   animation        0.00      0.00      0.00       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.51      0.44      0.47      1443\n",
      "       crime        0.00      0.00      0.00       107\n",
      " documentary        0.58      0.88      0.70      2659\n",
      "       drama        0.46      0.83      0.59      2697\n",
      "      family        1.00      0.01      0.01       150\n",
      "     fantasy        0.00      0.00      0.00        74\n",
      "   game-show        1.00      0.15      0.26        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.73      0.36      0.48       431\n",
      "       music        0.77      0.12      0.20       144\n",
      "     musical        0.00      0.00      0.00        50\n",
      "     mystery        0.00      0.00      0.00        56\n",
      "        news        0.00      0.00      0.00        34\n",
      "  reality-tv        0.80      0.02      0.04       192\n",
      "     romance        0.00      0.00      0.00       151\n",
      "      sci-fi        0.86      0.04      0.08       143\n",
      "       short        0.60      0.10      0.18      1045\n",
      "       sport        0.73      0.09      0.15        93\n",
      "   talk-show        0.00      0.00      0.00        81\n",
      "    thriller        0.23      0.01      0.02       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.98      0.59      0.74       200\n",
      "\n",
      "     accuracy                           0.52     10843\n",
      "    macro avg       0.41      0.14      0.16     10843\n",
      " weighted avg       0.52      0.52      0.44     10843\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_lr = lr_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_val, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_lr))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGGINJ7LMfN7",
    "outputId": "110b16fa-06ce-41c7-b2b8-4d5e86b49a9d"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic Regression Accuracy: 0.5794521811306834\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      action        0.53      0.27      0.35       263\n",
      "       adult        0.71      0.21      0.33       112\n",
      "   adventure        0.42      0.14      0.21       139\n",
      "   animation        0.61      0.11      0.18       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.51      0.58      0.55      1443\n",
      "       crime        0.43      0.03      0.05       107\n",
      " documentary        0.66      0.85      0.74      2659\n",
      "       drama        0.54      0.78      0.64      2697\n",
      "      family        0.41      0.07      0.12       150\n",
      "     fantasy        0.00      0.00      0.00        74\n",
      "   game-show        0.94      0.42      0.59        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.63      0.56      0.59       431\n",
      "       music        0.63      0.47      0.54       144\n",
      "     musical        1.00      0.02      0.04        50\n",
      "     mystery        0.00      0.00      0.00        56\n",
      "        news        1.00      0.06      0.11        34\n",
      "  reality-tv        0.47      0.18      0.26       192\n",
      "     romance        0.17      0.01      0.01       151\n",
      "      sci-fi        0.56      0.22      0.31       143\n",
      "       short        0.46      0.33      0.39      1045\n",
      "       sport        0.58      0.20      0.30        93\n",
      "   talk-show        0.62      0.12      0.21        81\n",
      "    thriller        0.40      0.15      0.22       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.95      0.70      0.80       200\n",
      "\n",
      "     accuracy                           0.58     10843\n",
      "    macro avg       0.49      0.24      0.28     10843\n",
      " weighted avg       0.55      0.58      0.54     10843\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_svm = svm_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_val, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_svm))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jet2LvF5Mibu",
    "outputId": "faf0d9f9-118c-4a15-e0f8-7235f4e54ae0"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVM Accuracy: 0.5853546066586738\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      action        0.49      0.36      0.41       263\n",
      "       adult        0.67      0.39      0.49       112\n",
      "   adventure        0.44      0.22      0.29       139\n",
      "   animation        0.54      0.14      0.23       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.52      0.60      0.56      1443\n",
      "       crime        0.17      0.02      0.03       107\n",
      " documentary        0.68      0.83      0.74      2659\n",
      "       drama        0.55      0.75      0.64      2697\n",
      "      family        0.28      0.07      0.12       150\n",
      "     fantasy        0.17      0.01      0.03        74\n",
      "   game-show        0.92      0.55      0.69        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.64      0.61      0.62       431\n",
      "       music        0.63      0.53      0.58       144\n",
      "     musical        0.60      0.06      0.11        50\n",
      "     mystery        0.50      0.04      0.07        56\n",
      "        news        0.40      0.06      0.10        34\n",
      "  reality-tv        0.52      0.26      0.34       192\n",
      "     romance        0.00      0.00      0.00       151\n",
      "      sci-fi        0.49      0.29      0.36       143\n",
      "       short        0.49      0.32      0.39      1045\n",
      "       sport        0.70      0.30      0.42        93\n",
      "   talk-show        0.57      0.20      0.29        81\n",
      "    thriller        0.40      0.15      0.22       309\n",
      "         war        0.50      0.05      0.09        20\n",
      "     western        0.92      0.77      0.84       200\n",
      "\n",
      "     accuracy                           0.59     10843\n",
      "    macro avg       0.47      0.28      0.32     10843\n",
      " weighted avg       0.55      0.59      0.55     10843\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "W30ZFAT7_PkM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_genre(user_input):\n",
    "    # Transform the user's input with the TF-IDF vectorizer\n",
    "    user_input_tfidf = tfidf_vectorizer.transform([user_input])\n",
    "\n",
    "    # Predictions from the models\n",
    "    nb_prediction = nb_model.predict(user_input_tfidf)\n",
    "    lr_prediction = lr_model.predict(user_input_tfidf)\n",
    "    svm_prediction = svm_model.predict(user_input_tfidf)\n",
    "\n",
    "    # Output predictions from all models\n",
    "    print(f\"Naive Bayes Prediction: {nb_prediction[0]}\")\n",
    "    print(f\"Logistic Regression Prediction: {lr_prediction[0]}\")\n",
    "    print(f\"SVM Prediction: {svm_prediction[0]}\")\n",
    "\n",
    "# Example of calling the function\n",
    "movie_description = input(\"Enter a movie description: \")\n",
    "predict_genre(movie_description)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MWtaycQv5M2U",
    "outputId": "42e9fc45-f13a-4e80-bbec-bf8ce271d3e1"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Enter a movie description: A superhero battles evil forces to save the world.\n",
      "Naive Bayes Prediction:  drama \n",
      "Logistic Regression Prediction:  horror \n",
      "SVM Prediction:  fantasy \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SZ5hWeyl5VHU"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
